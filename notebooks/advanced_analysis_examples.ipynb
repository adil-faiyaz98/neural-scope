{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Analysis Examples\n",
    "\n",
    "This notebook demonstrates how to use the advanced_analysis module for analyzing and optimizing machine learning code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import the necessary modules\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Add the parent directory to the path to import advanced_analysis\n",
    "sys.path.append('..')\n",
    "from advanced_analysis.analyzer import Analyzer\n",
    "from advanced_analysis.algorithm_complexity import StaticAnalyzer, DynamicAnalyzer, ComplexityAnalyzer\n",
    "from advanced_analysis.data_quality import DataGuardian, DataQualityReport\n",
    "from advanced_analysis.ml_advisor import MLAlgorithmRecognizer, InefficiencyDetector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Analyzing Code Complexity\n",
    "\n",
    "Let's start by analyzing the complexity of some Python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Define some sample code with different complexity patterns\n",
    "sample_code = \"\"\"\n",
    "def linear_search(arr, target):\n",
    "    for i in range(len(arr)):\n",
    "        if arr[i] == target:\n",
    "            return i\n",
    "    return -1\n",
    "\n",
    "def bubble_sort(arr):\n",
    "    n = len(arr)\n",
    "    for i in range(n):\n",
    "        for j in range(0, n - i - 1):\n",
    "            if arr[j] > arr[j + 1]:\n",
    "                arr[j], arr[j + 1] = arr[j + 1], arr[j]\n",
    "    return arr\n",
    "\n",
    "def binary_search(arr, target):\n",
    "    left, right = 0, len(arr) - 1\n",
    "    while left <= right:\n",
    "        mid = (left + right) // 2\n",
    "        if arr[mid] == target:\n",
    "            return mid\n",
    "        elif arr[mid] < target:\n",
    "            left = mid + 1\n",
    "        else:\n",
    "            right = mid - 1\n",
    "    return -1\n",
    "\"\"\"\n",
    "\n",
    "# Create a static analyzer and analyze the code\n",
    "static_analyzer = StaticAnalyzer()\n",
    "results = static_analyzer.analyze_code(sample_code)\n",
    "\n",
    "# Display the results\n",
    "print(\"Functions detected:\")\n",
    "for func_name, func_data in results[\"functions\"].items():\n",
    "    print(f\"  {func_name}: {func_data['time_complexity']}\")\n",
    "\n",
    "print(\"\\nOverall complexity:\")\n",
    "print(f\"  Time complexity: {results['overall_time_complexity']}\")\n",
    "print(f\"  Space complexity: {results['overall_space_complexity']}\")\n",
    "\n",
    "print(\"\\nDetected patterns:\")\n",
    "for pattern in results[\"detected_patterns\"]:\n",
    "    print(f\"  {pattern['pattern']}: {pattern['time_complexity']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dynamic Analysis of Functions\n",
    "\n",
    "Now, let's perform dynamic analysis to measure the actual performance of functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Define functions with different complexities\n",
    "def constant_time(n):\n",
    "    return 1\n",
    "\n",
    "def linear_time(n):\n",
    "    total = 0\n",
    "    for i in range(n):\n",
    "        total += i\n",
    "    return total\n",
    "\n",
    "def quadratic_time(n):\n",
    "    total = 0\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            total += i * j\n",
    "    return total\n",
    "\n",
    "# Create a dynamic analyzer\n",
    "dynamic_analyzer = DynamicAnalyzer()\n",
    "\n",
    "# Define an input generator\n",
    "def input_generator(size):\n",
    "    return size\n",
    "\n",
    "# Analyze the functions\n",
    "sizes = [10, 100, 1000]\n",
    "constant_results = dynamic_analyzer.analyze_function(constant_time, input_generator, sizes=sizes)\n",
    "linear_results = dynamic_analyzer.analyze_function(linear_time, input_generator, sizes=sizes)\n",
    "quadratic_results = dynamic_analyzer.analyze_function(quadratic_time, input_generator, sizes=sizes)\n",
    "\n",
    "# Display the results\n",
    "print(\"Constant time function:\")\n",
    "print(f\"  Estimated complexity: {constant_results['summary']['time_complexity']}\")\n",
    "\n",
    "print(\"\\nLinear time function:\")\n",
    "print(f\"  Estimated complexity: {linear_results['summary']['time_complexity']}\")\n",
    "\n",
    "print(\"\\nQuadratic time function:\")\n",
    "print(f\"  Estimated complexity: {quadratic_results['summary']['time_complexity']}\")\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(sizes, [constant_results['runtime']['average'][s] for s in sizes], 'o-', label='Constant')\n",
    "plt.plot(sizes, [linear_results['runtime']['average'][s] for s in sizes], 'o-', label='Linear')\n",
    "plt.plot(sizes, [quadratic_results['runtime']['average'][s] for s in sizes], 'o-', label='Quadratic')\n",
    "plt.xlabel('Input Size')\n",
    "plt.ylabel('Runtime (seconds)')\n",
    "plt.title('Runtime vs. Input Size')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Comprehensive Function Analysis\n",
    "\n",
    "Let's use the ComplexityAnalyzer to perform a comprehensive analysis of a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create a complexity analyzer for the quadratic time function\n",
    "complexity_analyzer = ComplexityAnalyzer(quadratic_time)\n",
    "\n",
    "# Analyze the function\n",
    "analysis_results = complexity_analyzer.analyze(inputs=[10, 100, 1000])\n",
    "\n",
    "# Display the results\n",
    "print(\"Function name:\", analysis_results[\"function_name\"])\n",
    "print(\"\\nTheoretical complexity:\")\n",
    "print(f\"  Big-O: {analysis_results['theoretical_complexity']['big_o']}\")\n",
    "print(f\"  Big-Theta: {analysis_results['theoretical_complexity']['big_theta']}\")\n",
    "print(f\"  Big-Omega: {analysis_results['theoretical_complexity']['big_omega']}\")\n",
    "\n",
    "print(\"\\nEmpirical performance:\")\n",
    "print(\"  Time measurements:\")\n",
    "for size, time in analysis_results[\"empirical_performance\"][\"time_measurements\"]:\n",
    "    print(f\"    Input size {size}: {time:.6f} seconds\")\n",
    "\n",
    "print(\"\\nOptimization suggestions:\")\n",
    "for suggestion in analysis_results[\"optimization_suggestions\"]:\n",
    "    print(f\"  [{suggestion['severity']}] {suggestion['message']}\")\n",
    "    print(f\"    {suggestion['details']}\")\n",
    "    if \"code_example\" in suggestion:\n",
    "        print(f\"    Example:\\n{suggestion['code_example']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Quality Analysis\n",
    "\n",
    "Let's analyze the quality of a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create a sample DataFrame with various data quality issues\n",
    "df = pd.DataFrame({\n",
    "    'id': [1, 2, 3, 4, 5, 5, 7],  # Duplicate value in id\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve', 'Frank', None],  # Missing value in name\n",
    "    'age': [25, 30, 35, 40, 45, 50, 200],  # Outlier in age\n",
    "    'salary': [50000, 60000, 70000, 80000, 90000, 100000, 110000],\n",
    "    'department': ['HR', 'IT', 'Finance', 'IT', 'HR', 'Finance', 'IT']\n",
    "})\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"Sample DataFrame:\")\n",
    "display(df)\n",
    "\n",
    "# Create a data guardian and analyze the data\n",
    "guardian = DataGuardian()\n",
    "report = guardian.generate_report(df)\n",
    "\n",
    "# Display the report\n",
    "print(\"\\nMissing values:\")\n",
    "print(f\"  Total missing: {report.missing_values['total_missing']}\")\n",
    "print(f\"  Missing by column: {report.missing_values['missing_by_column']}\")\n",
    "\n",
    "print(\"\\nDuplicates:\")\n",
    "print(f\"  Total duplicates: {report.duplicates['total_duplicates']}\")\n",
    "\n",
    "print(\"\\nOutliers:\")\n",
    "for column, outliers in report.outliers['outliers_by_column'].items():\n",
    "    print(f\"  {column}: {outliers}\")\n",
    "\n",
    "print(\"\\nData types:\")\n",
    "for column, dtype in report.data_types['column_types'].items():\n",
    "    print(f\"  {column}: {dtype}\")\n",
    "\n",
    "print(\"\\nValue distribution:\")\n",
    "for column, distribution in report.value_distribution['distribution_by_column'].items():\n",
    "    print(f\"  {column}: {distribution}\")\n",
    "\n",
    "# Generate an HTML report\n",
    "html_report = report.to_html()\n",
    "from IPython.display import HTML\n",
    "HTML(html_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ML Algorithm Recognition\n",
    "\n",
    "Let's identify ML algorithms in code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Define some ML code\n",
    "ml_code = \"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def train_linear_model(X, y):\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "    return model\n",
    "\n",
    "def train_classifier(X, y):\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    model.fit(X, y)\n",
    "    return model\n",
    "\n",
    "def train_forest(X, y):\n",
    "    model = RandomForestClassifier(n_estimators=100)\n",
    "    model.fit(X, y)\n",
    "    return model\n",
    "\n",
    "def train_svm(X, y):\n",
    "    model = SVC(kernel='rbf')\n",
    "    model.fit(X, y)\n",
    "    return model\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(10, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\"\"\"\n",
    "\n",
    "# Create an algorithm recognizer and analyze the code\n",
    "recognizer = MLAlgorithmRecognizer(ml_code)\n",
    "results = recognizer.analyze_code()\n",
    "\n",
    "# Display the results\n",
    "print(\"Identified algorithms:\")\n",
    "for algo in results[\"identified_algorithms\"]:\n",
    "    print(f\"  {algo['algorithm']}\")\n",
    "    print(f\"    Matched patterns: {algo['matched_patterns']}\")\n",
    "    print(f\"    Complexity: {algo['std_complexity']}\")\n",
    "\n",
    "print(\"\\nOptimization suggestions:\")\n",
    "for suggestion in results[\"optimization_suggestions\"]:\n",
    "    print(f\"  {suggestion['algorithm']}: {suggestion['suggestion']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Inefficiency Detection\n",
    "\n",
    "Let's detect inefficiencies in ML code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Define some inefficient ML code\n",
    "inefficient_code = \"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def process_dataframe(df):\n",
    "    results = []\n",
    "    for index, row in df.iterrows():\n",
    "        results.append(row['value'] * 2)\n",
    "    return results\n",
    "\n",
    "def compute_pairwise_distances(data):\n",
    "    n = len(data)\n",
    "    distances = []\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i != j:\n",
    "                distances.append(abs(data[i] - data[j]))\n",
    "    return distances\n",
    "\n",
    "def train_epoch(model, dataloader, criterion, optimizer):\n",
    "    for batch in dataloader:\n",
    "        inputs, targets = batch\n",
    "        inputs = inputs.cuda()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets.cuda())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Move back to CPU for processing\n",
    "        outputs = outputs.cpu()\n",
    "\"\"\"\n",
    "\n",
    "# Create an inefficiency detector and analyze the code\n",
    "detector = InefficiencyDetector(inefficient_code)\n",
    "results = detector.analyze_code()\n",
    "\n",
    "# Display the results\n",
    "print(\"Detected inefficiencies:\")\n",
    "for inefficiency in results[\"detected_inefficiencies\"]:\n",
    "    print(f\"  {inefficiency['name']}: {inefficiency['description']}\")\n",
    "    print(f\"    Severity: {inefficiency['severity']}\")\n",
    "    print(f\"    Suggestion: {inefficiency['suggestion']}\")\n",
    "\n",
    "print(\"\\nOptimization suggestions:\")\n",
    "for suggestion in results[\"optimization_suggestions\"]:\n",
    "    print(f\"  [{suggestion['severity']}] {suggestion['message']}\")\n",
    "    print(f\"    {suggestion['details']}\")\n",
    "    print(f\"    Example:\\n{suggestion['code_example']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Using the Main Analyzer\n",
    "\n",
    "Finally, let's use the main Analyzer to perform a comprehensive analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create an analyzer\n",
    "analyzer = Analyzer()\n",
    "\n",
    "# Analyze the inefficient code\n",
    "results = analyzer.analyze_code(inefficient_code)\n",
    "\n",
    "# Display the results\n",
    "print(\"Static analysis:\")\n",
    "print(f\"  Overall time complexity: {results['static_analysis']['overall_time_complexity']}\")\n",
    "\n",
    "print(\"\\nAlgorithm recognition:\")\n",
    "if \"identified_algorithms\" in results[\"algorithm_recognition\"]:\n",
    "    for algo in results[\"algorithm_recognition\"][\"identified_algorithms\"]:\n",
    "        print(f\"  {algo['algorithm']}\")\n",
    "else:\n",
    "    print(\"  No algorithms identified\")\n",
    "\n",
    "print(\"\\nVectorization analysis:\")\n",
    "print(f\"  Naive loops: {len(results['vectorization_analysis']['naive_loops'])}\")\n",
    "\n",
    "print(\"\\nInefficiencies:\")\n",
    "for inefficiency in results[\"inefficiencies\"]:\n",
    "    print(f\"  {inefficiency['type']}: {inefficiency.get('pattern', '')}\")\n",
    "\n",
    "print(\"\\nOptimization suggestions:\")\n",
    "for suggestion in results[\"optimization_suggestions\"]:\n",
    "    if isinstance(suggestion, dict) and \"message\" in suggestion:\n",
    "        print(f\"  {suggestion['message']}\")\n",
    "    elif isinstance(suggestion, dict) and \"suggestion\" in suggestion:\n",
    "        print(f\"  {suggestion['suggestion']}\")\n",
    "    else:\n",
    "        print(f\"  {suggestion}\")\n",
    "\n",
    "# Generate a report\n",
    "report = analyzer.generate_report(results, format=\"html\")\n",
    "HTML(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
